{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e57a2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import json\n",
    "from lib.mc_net import mc_model, costCriterionReaching\n",
    "from lib.some import reduct\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b6b9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# time-settings\n",
    "dh = 1e-2 # 10 ms sim-step\n",
    "duration = 1.2 # 600+200 ms\n",
    "T = int(round(duration/dh))\n",
    "# load inputs\n",
    "with open('TARGET_train.json') as f:\n",
    "    prms = json.load(f)    \n",
    "home_joint_state = np.array(prms['home_join'])\n",
    "home_cart_state = np.array(prms['home_cart'])\n",
    "cart_targ = np.array(prms['cart_targ'])\n",
    "cart_targ = torch.from_numpy(cart_targ).float()\n",
    "vel = np.array(prms['nor_vel'])\n",
    "vel = torch.from_numpy(vel[:-10]).float()\n",
    "# colormap\n",
    "cm = sns.color_palette(\"RdYlBu\", 8)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE' # you can neglect this (just my env met some problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0531f50-cefe-492c-8057-33cee0e9da0c",
   "metadata": {},
   "source": [
    "# baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263e592-bf46-4f7b-9857-8a0a11dd6cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('isn_o', exist_ok=True) \n",
    "os.makedirs('log', exist_ok=True) \n",
    "seed = 2023\n",
    "torch.manual_seed(seed)            \n",
    "torch.cuda.manual_seed(seed) \n",
    "reach_sim = mc_model(dh, torch.from_numpy(home_joint_state).float(), torch.from_numpy(home_cart_state).float())\n",
    "\n",
    "lrate = 2e-4 \n",
    "\n",
    "optim_params = (\n",
    "    [reach_sim.xstars_prms] +\n",
    "    list(reach_sim.mc_inplayer.parameters()) +\n",
    "    [reach_sim.c_prms]\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(optim_params, lr=lrate, weight_decay=1e-6)   \n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9991) # lr_now = lr * exp(step of epoch)\n",
    "# optim.lr_scheduler.StepLR\n",
    "\n",
    "# inters\n",
    "inters = 1000\n",
    "total_loss_for_plotting = np.empty(0)\n",
    "\n",
    "tic = time.time()\n",
    "for it in range(inters):\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    kinematics = reach_sim.forward(T, cart_targ, 'all')\n",
    "    loss = costCriterionReaching(reach_sim, cart_targ, torch.stack(kinematics))  \n",
    "    loss.backward(retain_graph=True) \n",
    "    optimizer.step()\n",
    "\n",
    "    # learning rate schedual\n",
    "    # scheduler.step() \n",
    "    total_loss_for_plotting = np.append(total_loss_for_plotting, loss.item())\n",
    "\n",
    "    sys.stdout.write(f'\\r iteration {it+1}/{inters} | train loss: {loss.item():.5f}')\n",
    "    sys.stdout.flush()\n",
    "    plt.plot(total_loss_for_plotting)\n",
    "    plt.title('The loss is %.5f of iter %d'%(loss.item(),it))\n",
    "\n",
    "    plt.savefig('log/isn.png')\n",
    "    plt.clf()  # release the memory of figure\n",
    "    plt.cla()  \n",
    "    if (it+1)%100 == 0 and it>500:\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(7*3, 5*2)) \n",
    "        axs = axs.ravel()\n",
    "        axs[0].plot(torch.stack(kinematics)[:,:,0].data.numpy(), torch.stack(kinematics)[:,:,1].data.numpy())        \n",
    "        axs[0].plot(cart_targ[:,0].data.numpy(), cart_targ[:,1].data.numpy(), 'o')\n",
    "        axs[0] .set_title('joint space')\n",
    "        \n",
    "        axs[1].plot(torch.stack(reach_sim.inp_list)[:, 0, :].data.numpy())\n",
    "        axs[1] .set_title('network input before tanh')\n",
    "        \n",
    "        axs[2].plot(torch.stack(reach_sim.networkactivity_list)[:, 0, :200].data.numpy())\n",
    "        axs[2] .set_title('neural activity')\n",
    "        \n",
    "        axs[3].plot(torch.stack(reach_sim.mus_out_list)[:, 0, :].data.numpy())\n",
    "        axs[3] .set_title('muscle activity')\n",
    "        \n",
    "        axs[4].plot(torch.stack(kinematics)[:,:,2].data.numpy())  \n",
    "        axs[4] .set_title('velocity')\n",
    "        \n",
    "        axs[5].plot(torch.stack(reach_sim.networkactivity_list)[:, -2, :200].data.numpy())\n",
    "        axs[5] .set_title('neural activity')\n",
    "        plt.savefig(\"isn_o/m_ep{}_{}.png\".format(it+1,total_loss_for_plotting[it]))\n",
    "        plt.close('all')\n",
    "        torch.save(reach_sim,\"isn_o/m_mep{}_{}.pt\".format(it+1,total_loss_for_plotting[it]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e3260",
   "metadata": {},
   "source": [
    "# no velocity feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a45d501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iteration 1000/1000 | train loss: 0.00388"
     ]
    }
   ],
   "source": [
    "os.makedirs('isn_o\\\\novel', exist_ok=True) \n",
    "seed = 2023\n",
    "torch.manual_seed(seed)            \n",
    "torch.cuda.manual_seed(seed) \n",
    "reach_sim = mc_model(dh, torch.from_numpy(home_joint_state).float(), torch.from_numpy(home_cart_state).float())\n",
    "\n",
    "lrate = 2e-4 \n",
    "\n",
    "optim_params = (\n",
    "    [reach_sim.xstars_prms] +\n",
    "    list(reach_sim.mc_inplayer.parameters()) +\n",
    "    [reach_sim.c_prms]\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(optim_params, lr=lrate, weight_decay=1e-6)   \n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9992) # lr_now = lr * exp(step of epoch)\n",
    "# optim.lr_scheduler.StepLR\n",
    "\n",
    "# inters\n",
    "inters = 1000\n",
    "total_loss_for_plotting_vel = np.empty(0)\n",
    "\n",
    "tic = time.time()\n",
    "for it in range(inters):\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    kinematics = reach_sim.forward(T, cart_targ, 'novel')\n",
    "    loss = costCriterionReaching(reach_sim, cart_targ, torch.stack(kinematics))     \n",
    "    loss.backward(retain_graph=True) \n",
    "    optimizer.step()\n",
    "\n",
    "    # learning rate schedual\n",
    "    # scheduler.step() \n",
    "    total_loss_for_plotting_vel = np.append(total_loss_for_plotting_vel, loss.item())\n",
    "\n",
    "    sys.stdout.write(f'\\r iteration {it+1}/{inters} | train loss: {loss.item():.5f}')\n",
    "    sys.stdout.flush()\n",
    "    plt.plot(total_loss_for_plotting_vel)\n",
    "    plt.title('The loss is %.5f of iter %d'%(loss.item(),it))\n",
    "\n",
    "    plt.savefig('log/novel.png')\n",
    "    plt.clf()  # release the memory of figure\n",
    "    plt.cla()  \n",
    "    if (it+1)%100 == 0 :\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(7*3, 5*2)) \n",
    "        axs = axs.ravel()\n",
    "        axs[0].plot(torch.stack(kinematics)[:,:,0].data.numpy(), torch.stack(kinematics)[:,:,1].data.numpy())        \n",
    "        axs[0].plot(cart_targ[:,0].data.numpy(), cart_targ[:,1].data.numpy(), 'o')\n",
    "        axs[0] .set_title('joint space')\n",
    "        \n",
    "        axs[1].plot(torch.stack(reach_sim.inp_list)[:, 0, :].data.numpy())\n",
    "        axs[1] .set_title('network input before tanh')\n",
    "        \n",
    "        axs[2].plot(torch.stack(reach_sim.networkactivity_list)[:, 0, :200].data.numpy())\n",
    "        axs[2] .set_title('neural activity')\n",
    "        \n",
    "        axs[3].plot(torch.stack(reach_sim.mus_out_list)[:, 0, :].data.numpy())\n",
    "        axs[3] .set_title('muscle activity')\n",
    "        \n",
    "        axs[4].plot(torch.stack(kinematics)[:,:,2].data.numpy())  \n",
    "        axs[4] .set_title('velocity')\n",
    "        \n",
    "        axs[5].plot(torch.stack(reach_sim.networkactivity_list)[:, -2, :200].data.numpy())\n",
    "        axs[5] .set_title('neural activity')\n",
    "        plt.savefig(\"isn_o/novel/m_ep{}_{}.png\".format(it+1,total_loss_for_plotting_vel[it]))\n",
    "\n",
    "        plt.close('all')\n",
    "        torch.save(reach_sim,\"isn_o/novel/m_ep{}_{}.pt\".format(it+1,total_loss_for_plotting_vel[it]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a83003-c95a-454c-a912-47f4f3a99a17",
   "metadata": {},
   "source": [
    "# no muscle force feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7408be94-ab0f-49c1-825d-acbd5c0d9ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iteration 1000/1000 | train loss: 0.00507"
     ]
    }
   ],
   "source": [
    "os.makedirs('isn_o\\\\nomus', exist_ok=True) \n",
    "seed = 2023\n",
    "torch.manual_seed(seed)            \n",
    "torch.cuda.manual_seed(seed) \n",
    "reach_sim = mc_model(dh, torch.from_numpy(home_joint_state).float(), torch.from_numpy(home_cart_state).float())\n",
    "\n",
    "lrate = 2e-4 \n",
    "optim_params = (\n",
    "    [reach_sim.xstars_prms] +\n",
    "    list(reach_sim.mc_inplayer.parameters()) +\n",
    "    [reach_sim.c_prms]\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(optim_params, lr=lrate, weight_decay=1e-6)   \n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9992) # lr_now = lr * exp(step of epoch)\n",
    "# optim.lr_scheduler.StepLR\n",
    "\n",
    "# inters\n",
    "inters = 1000\n",
    "\n",
    "total_loss_for_plotting_mus = np.empty(0)\n",
    "\n",
    "tic = time.time()\n",
    "for it in range(inters):\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    kinematics = reach_sim.forward(T, cart_targ, 'nomus')\n",
    "    loss = costCriterionReaching(reach_sim, cart_targ, torch.stack(kinematics))    \n",
    "    loss.backward(retain_graph=True) \n",
    "    optimizer.step()\n",
    "\n",
    "    # learning rate schedual\n",
    "    # scheduler.step() \n",
    "    total_loss_for_plotting_mus = np.append(total_loss_for_plotting_mus, loss.item())\n",
    "\n",
    "    sys.stdout.write(f'\\r iteration {it+1}/{inters} | train loss: {loss.item():.5f}')\n",
    "    sys.stdout.flush()\n",
    "    plt.plot(total_loss_for_plotting_mus)\n",
    "    plt.title('The loss is %.5f of iter %d'%(loss.item(),it))\n",
    "\n",
    "    plt.savefig('log/nmus.png')\n",
    "    plt.clf()  # release the memory of figure\n",
    "    plt.cla()  \n",
    "    if (it+1)%100 == 0 :\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(7*3, 5*2)) \n",
    "        axs = axs.ravel()\n",
    "        axs[0].plot(torch.stack(kinematics)[:,:,0].data.numpy(), torch.stack(kinematics)[:,:,1].data.numpy())        \n",
    "        axs[0].plot(cart_targ[:,0].data.numpy(), cart_targ[:,1].data.numpy(), 'o')\n",
    "        axs[0] .set_title('joint space')\n",
    "        \n",
    "        axs[1].plot(torch.stack(reach_sim.inp_list)[:, 0, :].data.numpy())\n",
    "        axs[1] .set_title('network input before tanh')\n",
    "        \n",
    "        axs[2].plot(torch.stack(reach_sim.networkactivity_list)[:, 0, :200].data.numpy())\n",
    "        axs[2] .set_title('neural activity')\n",
    "        \n",
    "        axs[3].plot(torch.stack(reach_sim.mus_out_list)[:, 0, :].data.numpy())\n",
    "        axs[3] .set_title('muscle activity')\n",
    "        \n",
    "        axs[4].plot(torch.stack(kinematics)[:,:,2].data.numpy())  \n",
    "        axs[4] .set_title('velocity')\n",
    "        \n",
    "        axs[5].plot(torch.stack(reach_sim.networkactivity_list)[:, -2, :200].data.numpy())\n",
    "        axs[5] .set_title('neural activity')\n",
    "        plt.savefig(\"isn_o/nomus/m_ep{}_{}.png\".format(it+1,total_loss_for_plotting_mus[it]))\n",
    "\n",
    "        plt.close('all')\n",
    "        torch.save(reach_sim,\"isn_o/nomus/m_ep{}_{}.pt\".format(it+1,total_loss_for_plotting_mus[it]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6cfdb8-11f2-4b68-b983-6acd4eef8967",
   "metadata": {},
   "source": [
    "# no velocity and muscle force feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5321d47a-e040-4b92-9fbf-c2bc00b25e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iteration 1000/1000 | train loss: 0.00408"
     ]
    }
   ],
   "source": [
    "os.makedirs('isn_o\\\\only', exist_ok=True) \n",
    "seed = 2023\n",
    "torch.manual_seed(seed)            \n",
    "torch.cuda.manual_seed(seed) \n",
    "reach_sim = mc_model(dh, torch.from_numpy(home_joint_state).float(), torch.from_numpy(home_cart_state).float())\n",
    "\n",
    "lrate = 2e-4 \n",
    "optim_params = (\n",
    "    [reach_sim.xstars_prms] +\n",
    "    list(reach_sim.mc_inplayer.parameters()) +\n",
    "    [reach_sim.c_prms]\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(optim_params, lr=lrate, weight_decay=1e-6)   \n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9992) # lr_now = lr * exp(step of epoch)\n",
    "# optim.lr_scheduler.StepLR\n",
    "\n",
    "# inters\n",
    "inters = 1000\n",
    "\n",
    "total_loss_for_plotting_ol = np.empty(0)\n",
    "\n",
    "tic = time.time()\n",
    "for it in range(inters):\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    kinematics = reach_sim.forward(T, cart_targ, 'only')\n",
    "    loss = costCriterionReaching(reach_sim, cart_targ, torch.stack(kinematics))    \n",
    "    loss.backward(retain_graph=True) \n",
    "    optimizer.step()\n",
    "\n",
    "    # learning rate schedual\n",
    "    # scheduler.step() \n",
    "    total_loss_for_plotting_ol = np.append(total_loss_for_plotting_ol, loss.item())\n",
    "\n",
    "    sys.stdout.write(f'\\r iteration {it+1}/{inters} | train loss: {loss.item():.5f}')\n",
    "    sys.stdout.flush()\n",
    "    plt.plot(total_loss_for_plotting_ol)\n",
    "    plt.title('The loss is %.5f of iter %d'%(loss.item(),it))\n",
    "\n",
    "    plt.savefig('log/only.png')\n",
    "    plt.clf()  # release the memory of figure\n",
    "    plt.cla()  \n",
    "    if (it+1)%100 == 0 :\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(7*3, 5*2)) \n",
    "        axs = axs.ravel()\n",
    "        axs[0].plot(torch.stack(kinematics)[:,:,0].data.numpy(), torch.stack(kinematics)[:,:,1].data.numpy())        \n",
    "        axs[0].plot(cart_targ[:,0].data.numpy(), cart_targ[:,1].data.numpy(), 'o')\n",
    "        axs[0] .set_title('joint space')\n",
    "        \n",
    "        axs[1].plot(torch.stack(reach_sim.inp_list)[:, 0, :].data.numpy())\n",
    "        axs[1] .set_title('network input before tanh')\n",
    "        \n",
    "        axs[2].plot(torch.stack(reach_sim.networkactivity_list)[:, 0, :200].data.numpy())\n",
    "        axs[2] .set_title('neural activity')\n",
    "        \n",
    "        axs[3].plot(torch.stack(reach_sim.mus_out_list)[:, 0, :].data.numpy())\n",
    "        axs[3] .set_title('muscle activity')\n",
    "        \n",
    "        axs[4].plot(torch.stack(kinematics)[:,:,2].data.numpy())  \n",
    "        axs[4] .set_title('velocity')\n",
    "        \n",
    "        axs[5].plot(torch.stack(reach_sim.networkactivity_list)[:, -2, :200].data.numpy())\n",
    "        axs[5] .set_title('neural activity')\n",
    "        plt.savefig(\"isn_o/only/m_ep{}_{}.png\".format(it+1,total_loss_for_plotting_ol[it]))\n",
    "\n",
    "        plt.close('all')\n",
    "        torch.save(reach_sim,\"isn_o/only/m_ep{}_{}.pt\".format(it+1,total_loss_for_plotting_ol[it]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5203043-c6dc-4f95-bd55-94e705570be1",
   "metadata": {},
   "source": [
    "# autonomous system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bda6df-26c5-4341-abc5-8f3a319392d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib.auto import mc_model, costCriterionReaching\n",
    "\n",
    "os.makedirs('isn_o\\\\auto', exist_ok=True) \n",
    "\n",
    "seed = 2023\n",
    "torch.manual_seed(seed)            \n",
    "torch.cuda.manual_seed(seed) \n",
    "reach_sim = mc_model(dh, torch.from_numpy(home_joint_state).float(), torch.from_numpy(home_cart_state).float())\n",
    "\n",
    "lrate = 2e-4 \n",
    "optim_params = (\n",
    "    [reach_sim.xstars_prms] +\n",
    "    list(reach_sim.mc_inplayer.parameters()) +\n",
    "    [reach_sim.c_prms]\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(optim_params, lr=lrate, weight_decay=1e-6)  \n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9991) \n",
    "# optim.lr_scheduler.StepLR\n",
    "\n",
    "# inters\n",
    "inters = 1000\n",
    "\n",
    "total_loss_for_plotting = np.empty(0)\n",
    "\n",
    "tic = time.time()\n",
    "for it in range(inters):\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    kinematics = reach_sim.forward(T, cart_targ)\n",
    "    loss = costCriterionReaching(reach_sim, cart_targ, torch.stack(kinematics))    \n",
    "    loss.backward(retain_graph=True) \n",
    "    optimizer.step()\n",
    "\n",
    "    # learning rate schedual\n",
    "    scheduler.step() \n",
    "    total_loss_for_plotting = np.append(total_loss_for_plotting, loss.item())\n",
    "\n",
    "    sys.stdout.write(f'\\r iteration {it+1}/{inters} | train loss: {loss.item():.5f}')\n",
    "    sys.stdout.flush()\n",
    "    plt.plot(total_loss_for_plotting)\n",
    "    plt.title('The loss is %.5f of iter %d'%(loss.item(),it))\n",
    "   \n",
    "    # plt.savefig('log/chaos.png')\n",
    "    plt.savefig('log/auto.png')\n",
    "    plt.clf()  \n",
    "    plt.cla()  \n",
    "    if (it+1)%100 == 0 :\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(7*3, 5*2)) \n",
    "        axs = axs.ravel()\n",
    "        axs[0].plot(torch.stack(kinematics)[:,:,0].data.numpy(), torch.stack(kinematics)[:,:,1].data.numpy())        \n",
    "        axs[0].plot(cart_targ[:,0].data.numpy(), cart_targ[:,1].data.numpy(), 'o')\n",
    "        axs[0] .set_title('joint space')\n",
    "        \n",
    "        # axs[1].plot(torch.stack(reach_sim.inp_list)[:, 0, :].data.numpy())\n",
    "        # axs[1] .set_title('network input before tanh')\n",
    "        \n",
    "        axs[2].plot(torch.stack(reach_sim.networkactivity_list)[:, 0, :200].data.numpy())\n",
    "        axs[2] .set_title('neural activity')\n",
    "        \n",
    "        axs[3].plot(torch.stack(reach_sim.mus_out_list)[:, 0, :].data.numpy())\n",
    "        axs[3] .set_title('muscle activity')\n",
    "        \n",
    "        axs[4].plot(torch.stack(kinematics)[:,:,2].data.numpy())  \n",
    "        axs[4] .set_title('velocity')\n",
    "\n",
    "        axs[5].plot(torch.stack(reach_sim.networkactivity_list)[:, -2, :200].data.numpy())\n",
    "        axs[5] .set_title('neural activity')\n",
    "        plt.savefig(\"isn_o/auto/m_ep{}_{}.png\".format(it+1,total_loss_for_plotting[it]))\n",
    "        plt.close('all')\n",
    "        torch.save(reach_sim,\"isn_o/auto/m_ep{}_{}.pt\".format(it+1,total_loss_for_plotting[it]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915fe5c-6bb0-42a5-800f-3dc1659c47ec",
   "metadata": {},
   "source": [
    "# other combination of feedback see in the 'choice' in mc_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd105df-2c3e-43ea-b058-c79816d8cd65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
